#  GoldValue Predictor

## 1. Project Overview

**GoldValue Predictor** is an academic project that applies **machine learning techniques** together with **project management practices** to predict gold prices using historical financial data.

The project demonstrates a complete end-to-end workflow, starting from problem definition and planning, through data analysis and model development, and ending with evaluation and deployment preparation.  
It is designed to show both **technical AI skills** and **structured project management**.



## 2. Problem Statement

Gold prices fluctuate daily due to global economic conditions, currency exchange rates, inflation, and geopolitical events.  
Predicting these price movements is challenging for investors and analysts.

This project aims to develop a predictive model that can **forecast gold closing prices** using historical data and engineered technical indicators to support informed decision-making.



## 3. Project Objectives

- Collect and preprocess historical gold price data
- Perform exploratory data analysis (EDA)
- Engineer relevant technical features
- Train and evaluate regression-based machine learning models
- Measure model performance using standard evaluation metrics
- Apply formal project management practices throughout the project lifecycle



## 4. Project Management Approach

The project was managed using a **structured project management framework**, aligned with academic standards and inspired by **CRISP-DM** and **PMBOK** principles.

### Project Phases
1. Business Understanding  
2. Data Understanding  
3. Data Preparation  
4. Modeling  
5. Evaluation  
6. Deployment Preparation & Monitoring  

Each phase is supported by documented planning, scheduling, risk management, quality control, and progress monitoring.



## 5. Data Source and Understanding

- **Data Source:** Yahoo Finance (via `yfinance`)
- **Instrument:** Gold Futures (GC=F)
- **Period Covered:** 2010 to present
- **Frequency:** Daily prices

The data is downloaded dynamically at runtime.  
No static dataset is stored in the repository to ensure:
- Real-time updates
- Reproducibility
- Compliance with data science best practices


## 6. Data Preparation & Exploratory Data Analysis (EDA)

### Data Cleaning
- Flattening multi-level column headers
- Handling missing values
- Ensuring consistent date and numeric formats

### Exploratory Analysis
- Time-series trend analysis of gold prices
- Distribution analysis of closing prices
- Correlation analysis between features

EDA helps identify trends, volatility, and relationships between variables before modeling.



## 7. Feature Engineering

To improve prediction performance, the following features were created:

- **SMA 15:** Short-term moving average  
- **SMA 30:** Long-term moving average  
- **Daily Return:** Volatility indicator  
- **Previous Close (Lag Feature):** Captures temporal dependency  

Rows containing NaN values generated by rolling calculations were removed to maintain data integrity.


## 8. Modeling Approach

### Model Type
- Regression-based machine learning models  
- Linear Regression used as the primary implementation

### Train–Test Strategy
- Chronological split (80% training, 20% testing)
- Prevents data leakage in time-series data

### Feature Scaling
- StandardScaler applied
- Fitted only on training data



## 9. Model Evaluation

Model performance is evaluated using standard regression metrics:

- **RMSE (Root Mean Squared Error)**
- **MAE (Mean Absolute Error)**
- **R² Score**

Additional evaluation includes:
- Residual analysis
- Visualization of actual vs predicted prices

These metrics measure accuracy, robustness, and explanatory power.



## 10. Deployment Preparation

GitHub does not execute Python code directly.  
However, the project is prepared for deployment through:

- Saved trained model (`.pkl`)
- Saved scaler (`.pkl`)
- Clean project structure
- Web interface design

The project can be deployed using platforms such as **Streamlit** or **Flask**, with GitHub serving as the version control and integration source.



## 11. Cost & Resource Management

### Resource Allocation
- **Human resources:** Student team members (data analysis, modeling, documentation)
- **Software:** Python, Pandas, NumPy, Scikit-learn, Matplotlib, Excel
- **Hardware:** CPU/GPU resources for model training

### Cost Assumptions
- Student / team member: **RM 25/hour**
- Specialist role (Data Analyst / ML Engineer): **RM 30/hour**
- GPU / cloud usage: **RM 10/hour**

### Budget Summary

| Cost Category | Cost (RM) |
|--------------|-----------|
| Human Resources | 570 |
| Hardware / Cloud | 80 |
| Software / Licenses | 0 |
| Communication & Miscellaneous | 120 |
| **Total Budget** | **770** |

Human resources represent the largest cost component.  
Cost control focused on limiting GPU usage and using open-source tools.



## 12. Risk & Quality Management

### Risk Management
Key risks identified include:
- Data inconsistency
- Lower-than-expected model accuracy
- Schedule delays
- Resource constraints

Mitigation strategies were applied through better data preprocessing, feature engineering, and schedule adjustments.

### Quality Management
Quality assurance focused on:
- Clean and validated datasets
- Acceptable error metrics (RMSE, MAE)
- Clear and readable visualizations
- Well-structured and documented code



## 13. Monitoring & Control

Project progress was monitored by:
- Comparing planned vs actual task completion
- Tracking milestones
- Applying corrective actions when delays were identified

This ensured the project remained aligned with scope, schedule, and budget.



## 14. Stakeholder & Communication Management

Key stakeholders include:
- Project team members
- Course lecturer and supervisor
- End users (students and investors)

Regular communication and documentation updates were used to manage expectations and project progress.









<img width="750" height="852" alt="image" src="https://github.com/user-attachments/assets/69cd6a08-29e4-49e6-b7dc-6055be7530b6" />
